{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa830272-2829-4e8e-afb1-e8b1be0517ce",
   "metadata": {},
   "source": [
    "## OpenAI에서 지원하는 GPT API 사용법을 알아보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0762880f-d300-4058-a5f1-f597989216f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.99.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\82108\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\82108\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\82108\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\82108\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\82108\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.99.1-py3-none-any.whl (767 kB)\n",
      "   ---------------------------------------- 0.0/767.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 767.8/767.8 kB 16.6 MB/s eta 0:00:00\n",
      "Downloading jiter-0.10.0-cp313-cp313-win_amd64.whl (205 kB)\n",
      "Installing collected packages: jiter, openai\n",
      "\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   ---------------------------------------- 2/2 [openai]\n",
      "\n",
      "Successfully installed jiter-0.10.0 openai-1.99.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e0d57b6-fa75-4d0c-89b4-09f3d50a655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "# 보안 정보를 화면에 표시없이 입력받을 때 사용하는 함수\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db41103a-8f3c-4eb9-a76e-f89f6ca279d1",
   "metadata": {},
   "source": [
    "### API Key 설정\n",
    "- API key는 잘못 유출되면 엄청난 금전적 손실을 볼 수 있으므로 감춰서 사용하는게 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f3aa57b-5afc-4772-9761-cbc4c1fb07b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI API Key : ········\n"
     ]
    }
   ],
   "source": [
    "MY_API_KEY = getpass.getpass(\"OpenAI API Key :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172dac4a-c133-401d-ba9c-6c1399541114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 객체 생성\n",
    "client = OpenAI(api_key=MY_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1688f1d-496c-4f99-96e0-b21a51dea36d",
   "metadata": {},
   "source": [
    "### GPT 채팅 모델 불러와서 일반적인 질의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ad12913-503d-4a86-93b6-8048ac385355",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"안녕, 오늘 정말 바다 가고싶은 날씨다\"\n",
    "\n",
    "# chat.completions.create : OpenAI의 채팅 API를 생성\n",
    "response = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
    "                                          # 질의 정보를 설정하는 인자(role은 역할 설정, content는 질의 내용)\n",
    "                                           # role은 'system', 'users', 'assistant' 중 한가지로 설정 가능\n",
    "                                           # system은 사용자의 질의가 입력되기 전에 모델에게 숙지시켜놓는 대전제나 규칙\n",
    "                                          messages=[{'role':'user', 'content':question}],\n",
    "                                          # 생성할 응답의 최대 토큰 수 지정(출력 테스트의 길이 지정)\n",
    "                                          max_tokens=150,\n",
    "                                          # temperature : 생성되는 응답의 창의성 정도를 조정해주는 인자\n",
    "                                           #              (0~2사이의 실수값, 0은 일관된 응답, 2는 창의적 응답)\n",
    "                                          temperature=0\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b244bf8-fde4-48aa-8e6e-33e6e57f0771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C1nAXklslIIZC733RYGvRmtBr5BbO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='안녕하세요! 바다로 가기 좋은 날씨라니 정말 좋네요. 햇살 가득한 날씨에서 바다를 즐기시면 정말 기분이 좋을 것 같아요. 즐거운 시간 보내세요!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1754543369, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=79, prompt_tokens=31, total_tokens=110, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c330ef4-0660-404b-83a8-9174ec5b0433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2a37a1-0e0a-4663-be4d-aa9102257502",
   "metadata": {},
   "source": [
    "#### ChatCompletion 객체에는 사용자의 요청과 모델의 응답에 대한 정보가 담겨져 있음\n",
    "- content에 실제 텍스트 응답이 있으며, role에는 역할, model에는 사용된 모델명, usage에는 토큰 사용량에 대한 정보가 들어있음\n",
    "- 모델이 응답할 때 role은 항상 assistant로 출력됨(우리가 질의할 때는 user로 질의해야 함)\n",
    "- usage에 prompt_tokens는 입력 토큰(질의)수, completions_tokens는 출력 토큰(응답)의 수가 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49862c1d-8ec9-43c5-9173-ff9b8d1b1f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chatcmpl-C1nAXklslIIZC733RYGvRmtBr5BbO'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "821ac314-866d-4c03-92ae-ee5dd8ed2d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='안녕하세요! 바다로 가기 좋은 날씨라니 정말 좋네요. 햇살 가득한 날씨에서 바다를 즐기시면 정말 기분이 좋을 것 같아요. 즐거운 시간 보내세요!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices   # 리스트 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75440442-517a-4ae0-92be-90a45fc4321b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='안녕하세요! 바다로 가기 좋은 날씨라니 정말 좋네요. 햇살 가득한 날씨에서 바다를 즐기시면 정말 기분이 좋을 것 같아요. 즐거운 시간 보내세요!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb566326-68f6-4655-adca-ac999f19da2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assistant'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.role   # role에 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c0a01fa-a213-40ac-bdfa-7e5659b69ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요! 바다로 가기 좋은 날씨라니 정말 좋네요. 햇살 가득한 날씨에서 바다를 즐기시면 정말 기분이 좋을 것 같아요. 즐거운 시간 보내세요!'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content    # 응답 텍스트 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac1315d-0dd7-4621-9fa9-44e7c824c527",
   "metadata": {},
   "source": [
    "### 자주 발생하는 코드 에러\n",
    "- RatelimitError : API크레딧 사용 한도를 초과한 경우\n",
    "- InvalidRequestError : 잘못된 요청이 발생한 경우\n",
    "- APIConnectionErrror : API 서버와의 연결 문제로 발생한 경우\n",
    "- OpenAIError : 기타 일반적인 openai라이브러리 사용 시 발생하는에러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0dd7ce11-6e5b-4919-be5b-16d7327af11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"drop_duplicates() 함수를 사용하여 pandas DataFrame에서 중복 항목을 제거할 수 있습니다. 이 함수는 중복된 행을 제거하고 유일한 값만 남기는 기능을 제공합니다. 예를 들어, 다음과 같이 drop_duplicates() 함수를 사용하여 중복 항목을 제거할 수 있습니다.\\n\\n```python\\nimport pandas as pd\\n\\n# 샘플 데이터프레임 생성\\ndata = {'A': [1, 1, 2, 2, 3],\\n        'B': ['a', 'a', 'b', 'b', 'c']}\\ndf = pd.DataFrame\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"pandas DataFrane에서 중복 항목을 제거하는 방법은?\"\n",
    "\n",
    "response = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
    "                                          messages=[{'role':'user', 'content':question}],\n",
    "                                          max_tokens=150,\n",
    "                                          temperature=0\n",
    "                                         )\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7055ba2-5b17-4835-b05f-2090aa05c3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_duplicates() 함수를 사용하여 pandas DataFrame에서 중복 항목을 제거할 수 있습니다. 이 함수는 중복된 행을 제거하고 유일한 값만 남기는 기능을 제공합니다. 예를 들어, 다음과 같이 drop_duplicates() 함수를 사용하여 중복 항목을 제거할 수 있습니다.\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# 샘플 데이터프레임 생성\n",
      "data = {'A': [1, 1, 2, 2, 3],\n",
      "        'B': ['a', 'a', 'b', 'b', 'c']}\n",
      "df = pd.DataFrame\n"
     ]
    }
   ],
   "source": [
    "#  프린트문으로 보기 좋게 출력\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2af34fd-2818-4078-87f7-4058b08c1bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'물론이죠. 어떤 종류의 제품이나 판매 데이터를 시각화하고 싶으신가요? 예를 들어, 음식점의 음식 판매량이나 온라인 쇼핑몰의 제품 판매량 등을 시각화할 수 있습니다. 자세한 정보를 알려주시면 해당 데이터에 맞는 막대 차트를 생성해드리겠습니다.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 없는 데이터에 대한 요청\n",
    "question = \"지난 1년간의 판매 데이터를 시각화하기 위한 막대 차트를 생성해줘.\"\n",
    "\n",
    "response = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
    "                                          messages=[{'role':'user', 'content':question}],\n",
    "                                          max_tokens=150,\n",
    "                                          temperature=0\n",
    "                                         )\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1e33abc-2f1c-47a3-afb9-95c10bed91d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"막대 차트를 생성하기 위해서는 먼저 판매 데이터를 준비해야 합니다. 데이터가 준비되었다고 가정하고, Python의 Matplotlib 라이브러리를 사용하여 막대 차트를 생성하는 방법을 설명하겠습니다. 아래는 예제 코드입니다.\\n\\n```python\\nimport matplotlib.pyplot as plt\\n\\n# 예제 데이터: 월별 판매량\\nmonths = ['1월', '2월', '3월', '4월', '5월', '6월', '7월', '8월', '9월', '10월', '11월', '12월']\\nsales = [150, 200, 250, 300, 350, 400, 450, 500, \""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"지난 1년간의 판매 데이터를 시각화하기 위한 막대 차트를 생성해줘.\"\n",
    "\n",
    "response = client.chat.completions.create(model=\"gpt-4o\",\n",
    "                                          messages=[{'role':'user', 'content':question}],\n",
    "                                          max_tokens=150,\n",
    "                                          temperature=0\n",
    "                                         )\n",
    "response.choices[0].message.content\n",
    "\n",
    "# 상위 모델의 성능이 훨씬 뛰어남\n",
    "# 현재는 ChatGPT 서비스를 이용하는게 아니라 API로 로컬에서 동작시키기 때문에 직접 시각화된 이미지가 나오지는 않고 코드로 제공함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e88eb8e0-c380-44cc-87f9-816467b5a9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 가격: 고객들은 가격이 비싸거나 경쟁사에 비해 높을 경우 이탈할 가능성이 높습니다.\n",
      "\n",
      "2. 콘텐츠: 다양하고 흥미로운 콘텐츠를 제공하지 않을 경우 고객들은 다른 서비스로 이탈할 수 있습니다.\n",
      "\n",
      "3. 서비스 품질: 서비스의 안정성, 속도, 사용자 경험 등이 만족스럽지 않을 경우 고객들은 이탈할 수 있습니다.\n",
      "\n",
      "4. 경쟁사와의 비교: 경쟁사가 더 나은 혜택이나 콘텐츠를 제공할 경우 고객들은 이탈할 가능성이 높습니다.\n",
      "\n",
      "5. 고객 서비스: 만족스러운 고객 서비스를 제공하지 않을 경우 고객들은 이탈할 수 있습니다.\n",
      "\n",
      "6. 이용 편의성: 서비스 이용이 복잡하거나 불편할 경우 고객들은 이탈할 가능성이 높습니다.\n",
      "\n",
      "7. 마케팅 활동: 적절한 마케팅 활동을 통해 고객들의 관심을 유지하지 못할 경우 이탈할 가능성이 높습니다.\n"
     ]
    }
   ],
   "source": [
    "question = \"OTT 구독 서비스에서 고객 이탈에 영향을 미치는 주요 요인은?\"\n",
    "\n",
    "response = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
    "                                          messages=[{'role':'user', 'content':question}],\n",
    "                                          temperature=0\n",
    "                                         )\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1203357-1c49-4c5b-93f7-9b3c34ff9c0d",
   "metadata": {},
   "source": [
    "### 입력된 파일에 대한 분석 요청\n",
    "- 파일과 질의를 구분해서 하나의 전체 질의로 구성한 사용자 정의 함수 만들기\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5d2b4a3-8b87-4032-8152-2be61129e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 위치를 data매개변수에, 질의를 question에, 모델명을 model에 넣게 됨\n",
    "def analysis_data(data, question, model) :\n",
    "    prompt = f\"Data: {data}, Question: {question}\"\n",
    "    response = client.chat.completions.create(model=model,\n",
    "                                              messages=[{'role':'user', 'content':prompt}]\n",
    "                                             )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0bf0d96-c6c4-4e26-b6c2-5caf8b021399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extremely Weak: 48\n",
      "Underweight: 92\n",
      "Normal: 170\n",
      "Overweight: 129\n",
      "Obesity I: 44\n",
      "Obesity II: 14\n",
      "Obesity III: 3\n"
     ]
    }
   ],
   "source": [
    "data = \"data/bmi_500.csv\"\n",
    "question = \"\"\"해당 데이터는 500명의 bmi점수에 대한 데이터야. Extremly Week 부터 Extremly Obesity까지 각각의 데이터의 개수를 파악해서 출력해줘.\"\"\"\n",
    "model = \"gpt-3.5-turbo\"\n",
    "\n",
    "result = analysis_data(data, question, model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12fe4186-3dbb-4013-be15-471a377915d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`data/bmi_500.csv` 파일을 분석하여 각 BMI 카테고리에 속하는 데이터의 개수를 확인하려면 Python의 pandas 라이브러리를 사용하면 됩니다. 이 작업을 수행하기 위해 간단한 스크립트를 작성할 수 있습니다. 이 스크립트는 CSV 파일을 읽고, 각 카테고리별로 데이터 개수를 계산하여 출력합니다.\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# CSV 파일을 읽어옵니다.\n",
      "file_path = 'data/bmi_500.csv'\n",
      "data = pd.read_csv(file_path)\n",
      "\n",
      "# BMI 점수에 따른 카테고리 개수를 계산합니다.\n",
      "category_counts = data['BMI_Category'].value_counts()\n",
      "\n",
      "# 각 카테고리의 개수를 출력합니다.\n",
      "print(category_counts)\n",
      "```\n",
      "\n",
      "이 코드는 다음과 같은 작업을 수행합니다:\n",
      "1. `pandas` 라이브러리를 사용하여 CSV 파일을 읽습니다.\n",
      "2. `value_counts()` 메서드를 사용하여 'BMI_Category' 열의 고유한 값의 빈도를 계산합니다.\n",
      "3. 각 카테고리별 데이터의 개수를 출력합니다.\n",
      "\n",
      "각 카테고리는 'Extremely Weak', 'Weak', 'Normal', 'Overweight', 'Obesity', 'Extremely Obesity'일 수 있으며, 이 스크립트를 실행하면 각각의 카테고리에 속한 개인의 수를 얻을 수 있습니다. CSV 파일의 구조가 다를 경우, 'BMI_Category'라는 열 이름을 실제 값에 맞게 조정해야 합니다.\n"
     ]
    }
   ],
   "source": [
    "data = \"data/bmi_500.csv\"\n",
    "question = \"\"\"해당 데이터는 500명의 bmi점수에 대한 데이터야. Extremly Week 부터 Extremly Obesity까지 각각의 데이터의 개수를 파악해서 출력해줘.\"\"\"\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "result = analysis_data(data, question, model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914723cb-ccdf-40ca-ba55-d370dda06853",
   "metadata": {},
   "source": [
    "### 정리\n",
    "- API를 활용하여 로컬 PC에서 결과를 출력하려 한다면 사용자별로 각기 다른 환경이기 때문에 시각화 요청에 대해 누구나 활용할 수 있는 코드 형태로 제공하는 경우가 많음\n",
    "- ChatGPT 웹 서비스에서 3.5 무료 버전은 파일 입력이 불가능하지만, API의 3.5버전은 로컬 pc의 파일을 입력시켜줄 수 있음\n",
    "- 기본적으로 상위 모델의 응답이 훨씬 퀄리티가 높으나 모든 응답이 정확성을 담보로 하지는 않기 때문에 100% 믿으면 리스크가 발생할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e536f4-12cf-44be-85f1-d1777cfd45e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb5f0e1-cf65-4278-b99d-46f207861cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc90558-d0cb-48e8-8cf2-951333f5b39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd6354-7ac3-4548-8b05-9ba34919e9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
